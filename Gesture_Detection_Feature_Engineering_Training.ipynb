{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yK5dqxUDmtTi"
      },
      "source": [
        "Run the following code block only if running on Google Colab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yJqT1ZFsdWHP",
        "outputId": "8c9f2ccf-719b-403d-aa20-a5c57102ca0e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nQxtSBvdsT-q"
      },
      "outputs": [],
      "source": [
        "# Import Libraries\n",
        "import os\n",
        "import math\n",
        "import pickle\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "from pathlib import Path\n",
        "from itertools import combinations\n",
        "\n",
        "# Sklearn\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.datasets import make_classification\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import cross_validate"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fo3NLOjbGpte"
      },
      "source": [
        "### Herlper Variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zG44zpVavbFa"
      },
      "outputs": [],
      "source": [
        "keypoints_of_interest = [\n",
        "     \"left_shoulder\", \"right_shoulder\", \"left_elbow\", \"right_elbow\", \"left_wrist\", \"right_wrist\"\n",
        "]\n",
        "\n",
        "connections_of_interest = {\n",
        "    \"left_upper_arm\" : [\"left_shoulder\", \"left_elbow\"],\n",
        "    \"left_lower_arm\" : [\"left_elbow\", \"left_wrist\"],\n",
        "    \"right_upper_arm\" : [\"right_shoulder\", \"right_elbow\"],\n",
        "    \"right_lower_arm\" : [\"right_elbow\", \"right_wrist\"]\n",
        "}\n",
        "\n",
        "data_attr_of_interest = [\n",
        "    kp + \"_\" + coord\n",
        "    for kp in keypoints_of_interest\n",
        "    for coord in [\"x\",\"y\"]\n",
        "]\n",
        "\n",
        "connection_combinations = list(combinations(connections_of_interest.keys(), 2))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vTl4x574GlVZ"
      },
      "source": [
        "### Helper Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CQt2YkN4GkN7"
      },
      "outputs": [],
      "source": [
        "def dot(vA, vB):\n",
        "    return vA[0]*vB[0]+vA[1]*vB[1]\n",
        "\n",
        "def make_short_form(name):\n",
        "  return \"\".join([word[0].upper() for word in name.split(\"_\")])\n",
        "\n",
        "def to_ij_vector(coordinates):\n",
        "  return [(round(coordinates[1][0]-coordinates[0][0],4)), (round(coordinates[1][1]-coordinates[0][1],2))]\n",
        "\n",
        "def ang(vA, vB):\n",
        "    try:\n",
        "      # Get dot prod\n",
        "      dot_prod = dot(vA, vB)\n",
        "      # Get magnitudes\n",
        "      magA = dot(vA, vA)**0.5\n",
        "      magB = dot(vB, vB)**0.5\n",
        "      # Get cosine value\n",
        "      cos_ = dot_prod/magA/magB\n",
        "      # Get angle in radians and then convert to degrees\n",
        "      angle = math.acos(dot_prod/magB/magA)\n",
        "      # Basically doing angle <- angle mod 360\n",
        "      ang_deg = math.degrees(angle)%360\n",
        "\n",
        "      if ang_deg-180>=0:\n",
        "          # As in if statement\n",
        "          return 360 - ang_deg\n",
        "      else:\n",
        "\n",
        "          return ang_deg\n",
        "    except Exception as e:\n",
        "      print(e, \":\", vA, vB)\n",
        "      return 0\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0oJCtkfjGYpV"
      },
      "source": [
        "## Train the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aBRMI3AaVa5z"
      },
      "source": [
        "### Key variables for training the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ydTw5XzInAo4"
      },
      "source": [
        "**** Specify root directory *****"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AIJkluTem-pK"
      },
      "outputs": [],
      "source": [
        "root_dir = Path(\"/content/drive/MyDrive/gestures_dataset_new/keypoints\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jhq68WqPVYLn"
      },
      "outputs": [],
      "source": [
        "# Key Variables\n",
        "\n",
        "# Paths to the folder containing keypoints csvs\n",
        "\n",
        "training_data_path = root_dir / \"train\"\n",
        "testing_data_path = root_dir / \"test\"\n",
        "\n",
        "# Where and what to save the model files as\n",
        "save_model_as = root_dir / \"feature_engineering_model.sklearn-1-2-2.pickle\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mr-wUsqIVY8Y"
      },
      "source": [
        "### Training Methods - data reading and feature geenrations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_OhCIrgODyhG"
      },
      "outputs": [],
      "source": [
        "# Helper function for applying get_features method for a group of frames belonging to a single video file.\n",
        "def remove_non_csv_files(directory_contents):\n",
        "    for file in directory_contents:\n",
        "        if file[-3:] != 'csv':\n",
        "            print(\"Excluded file: \", file)\n",
        "            directory_contents.remove(file)\n",
        "    return directory_contents\n",
        "\n",
        "def get_video_features(group):\n",
        "  '''\n",
        "  Arguments:\n",
        "    groups  pandas.groups object\n",
        "\n",
        "  Returns:\n",
        "    pandas.series object\n",
        "  '''\n",
        "  group = group.sort_values(by=\"frame_sequence\").drop(columns=[\"frame_sequence\"])\n",
        "  return get_features(group)\n",
        "\n",
        "# Compile test/train data df\n",
        "def compile_data_df(data_path):\n",
        "  '''\n",
        "  path  location to the folder that contains subfolders - hand_waving, pointing, other\n",
        "\n",
        "  '''\n",
        "  data_path = Path(data_path)\n",
        "  data_df = pd.DataFrame()\n",
        "  subfolders = [item for item in os.listdir(data_path) if os.path.isdir(data_path / item)]\n",
        "  for subfolder in subfolders:\n",
        "    files = os.listdir(data_path / subfolder)\n",
        "    files = remove_non_csv_files(files)\n",
        "    for file in files:\n",
        "      df = pd.read_csv(data_path / subfolder / file)\n",
        "      df[\"filename\"] = file\n",
        "      df[\"frame_sequence\"] = range(1, len(df)+1)\n",
        "      df[\"label\"]=subfolder\n",
        "      data_df = pd.concat([df, data_df])\n",
        "  return data_df\n",
        "\n",
        "# Function to spit out features given frames and keypoints\n",
        "def get_features(df):\n",
        "  data = df[data_attr_of_interest].dropna()\n",
        "\n",
        "  for val in keypoints_of_interest:\n",
        "    data[val] = list(zip(data[f\"{val}_x\"], data[f\"{val}_y\"]))\n",
        "\n",
        "  for connection, (keypoint1, keypoint2) in connections_of_interest.items():\n",
        "    data[connection] = list(zip(data[keypoint1], data[keypoint2]))\n",
        "\n",
        "  # Converting to i j vectors\n",
        "  for connection in connections_of_interest:\n",
        "    data[connection] = data[connection].apply(to_ij_vector)\n",
        "\n",
        "  # Connection vector angles\n",
        "  rest_pos_vector = [0,-1] # downward, -j unit vector\n",
        "\n",
        "  for connection in connections_of_interest:\n",
        "    data[connection + \"_angle\"] = data[connection].apply(ang, vB=rest_pos_vector)\n",
        "\n",
        "  # Feature - Ratio of angles lower angle:higher angle of anlge between left upper and lower arm and for right\n",
        "  ratios = []\n",
        "\n",
        "  for idx, row in data.iterrows():\n",
        "    left_arm_angle = ang(row[\"left_upper_arm\"], row[\"left_lower_arm\"])\n",
        "    right_arm_angle = ang(row[\"right_upper_arm\"], row[\"right_lower_arm\"])\n",
        "    ratios.append(round(min([left_arm_angle, right_arm_angle])*100/max([left_arm_angle, right_arm_angle]),4))\n",
        "\n",
        "  data[\"arm_angle_ratio\"] = ratios\n",
        "\n",
        "  # Ratio of y of wrists positions\n",
        "  ratios = []\n",
        "\n",
        "  for idx, row in data.iterrows():\n",
        "    min_y = min([row[\"left_wrist_y\"], row[\"right_wrist_y\"]])\n",
        "    max_y = max([row[\"left_wrist_y\"], row[\"right_wrist_y\"]])\n",
        "    ratios.append(round(min_y*100/max_y,4))\n",
        "\n",
        "  data[\"wrist_y_ratio\"] = ratios\n",
        "\n",
        "  # Difference of angle between each connection combination\n",
        "  for connection1, connection2 in connection_combinations:\n",
        "    data[f\"{make_short_form(connection1)}_{make_short_form(connection2)}\"] = (data[connection1 + \"_angle\"] - data[connection2 + \"_angle\"]).abs()\n",
        "\n",
        "  # Ratio of y of wrist vs shoulder positions\n",
        "  ratios = []\n",
        "\n",
        "  for idx, row in data.iterrows():\n",
        "    left = abs(row[\"left_wrist_y\"] - row[\"left_shoulder_y\"])\n",
        "    right = abs(row[\"right_wrist_y\"] - row[\"right_shoulder_y\"])\n",
        "    ratios.append(round(min([left,right])*100/max([left,right]),4))\n",
        "\n",
        "  data[\"wrist_shoulder_y_ratio\"] = ratios\n",
        "\n",
        "  # Start summarizing\n",
        "  starting_col_idx = data.columns.tolist().index(\"left_upper_arm_angle\")\n",
        "\n",
        "  features_video = {}\n",
        "\n",
        "  for col in data.columns[starting_col_idx:]:\n",
        "    features_video[f\"{col}_min\"] = data[col].min().tolist()\n",
        "    features_video[f\"{col}_max\"] = data[col].max().tolist()\n",
        "    features_video[f\"{col}_mean\"] = data[col].mean().tolist()\n",
        "    features_video[f\"{col}_median\"] = data[col].median().tolist()\n",
        "    features_video[f\"{col}_var\"] = data[col].var().tolist()\n",
        "\n",
        "  return pd.Series(features_video).sort_index()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NmP5aFHnXNEf"
      },
      "source": [
        "### Prepare training data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4XxRl1LjuQWZ",
        "outputId": "61129b09-95cf-457b-b480-95a428945e26"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "float division by zero : [0.0, 0.0] [0, -1]\n",
            "float division by zero : [0.0, 0.0] [0, -1]\n",
            "float division by zero : [0.0, 0.0] [0, -1]\n",
            "float division by zero : [0.0, 0.0] [0, -1]\n",
            "float division by zero : [0.0, 0.0] [0, -1]\n",
            "float division by zero : [0.0, 373.21] [0.0, 0.0]\n",
            "float division by zero : [0.0, 382.18] [0.0, 0.0]\n",
            "math domain error : [0.0, 239.67] [0.0, 139.22]\n",
            "float division by zero : [0.0, 382.02] [0.0, 0.0]\n",
            "float division by zero : [0.0, 376.38] [0.0, 0.0]\n",
            "float division by zero : [0.0, 377.59] [0.0, 0.0]\n"
          ]
        }
      ],
      "source": [
        "# Convert path strings to pathlib's Path object\n",
        "training_data_path = Path(training_data_path)\n",
        "\n",
        "# Read all the files and compiled them into single dataframe\n",
        "training_data = compile_data_df(training_data_path)\n",
        "\n",
        "# (Optional) Save the data as CSV\n",
        "training_data.to_csv(root_dir / \"training_data.csv\")\n",
        "\n",
        "# Extract labels from the training data\n",
        "Y_train = training_data.groupby([\"filename\"])[\"label\"].first().tolist()\n",
        "\n",
        "# Get features and prepare training data\n",
        "X_train = training_data.drop(columns=[\"label\"])\\\n",
        "                        .groupby([\"filename\"])\\\n",
        "                        .apply(get_video_features)\\\n",
        "                        .to_numpy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GWJIYprhXTQV"
      },
      "source": [
        "### Train the model pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "POd56eI4Dqhe"
      },
      "outputs": [],
      "source": [
        "# Make Pipeline\n",
        "model_pipeline = make_pipeline(StandardScaler(),\n",
        "                    LinearSVC(random_state=0, tol=1e-5))\n",
        "\n",
        "# Fit\n",
        "model_pipeline = model_pipeline.fit(X_train, Y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "LuqKoJzZQVuN"
      },
      "outputs": [],
      "source": [
        "# Save model pipeline\n",
        "with open(save_model_as, 'wb') as pickle_file:\n",
        "  pickle.dump(model_pipeline, pickle_file)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hlookqqzR5xR"
      },
      "source": [
        "## Test the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WIpvuw5KVwrE"
      },
      "source": [
        "### Key variables for testing the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "bAB4aXe_VxS7"
      },
      "outputs": [],
      "source": [
        "# Key Variables\n",
        "\n",
        "# Paths to the folder containing keypoints csvs for testing\n",
        "testing_data_path = root_dir / \"test\"\n",
        "\n",
        "# Location of model\n",
        "model_file_path = root_dir / \"feature_engineering_model.sklearn-1-2-2.pickle\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jK9t9SSFXaMw"
      },
      "source": [
        "### Prepare testing data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "U3GXSLciB5k0"
      },
      "outputs": [],
      "source": [
        "# Convert path strings to pathlib's Path object\n",
        "testing_data_path = Path(testing_data_path)\n",
        "\n",
        "# Read all the files and compiled them into single dataframe\n",
        "testing_data = compile_data_df(testing_data_path)\n",
        "\n",
        "# (Optional) Save the data as CSV\n",
        "testing_data.to_csv(root_dir / \"testing_data.csv\")\n",
        "\n",
        "# Extract true labels from the testing data\n",
        "Y_test = testing_data.groupby([\"filename\"])[\"label\"].first().tolist()\n",
        "\n",
        "# Get features and prepare testing data\n",
        "X_test = testing_data.drop(columns=[\"label\"])\\\n",
        "                        .groupby([\"filename\"])\\\n",
        "                        .apply(get_video_features)\\\n",
        "                        .to_numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wBeukQZ8XZTC",
        "outputId": "417d3884-7217-4732-b736-fd5e2317f346"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.95\n"
          ]
        }
      ],
      "source": [
        "# Load the saved model pipeline\n",
        "with open(model_file_path, 'rb') as pickle_file:\n",
        "  loaded_pipeline = pickle.load(pickle_file)\n",
        "\n",
        "# Predict for the test set\n",
        "Y_pred = loaded_pipeline.predict(X_test)\n",
        "\n",
        "# Print accuracy score for the test set\n",
        "print(accuracy_score(Y_test, Y_pred))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
